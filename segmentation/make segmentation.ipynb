{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emerging-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_float32, img_as_ubyte, img_as_float64\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    print(gpus)\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "img_size = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-stage",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlike-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_learning_rate = keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor = \"loss\", \n",
    "  factor = 0.5, \n",
    "  patience = 3, \n",
    "  verbose = 1\n",
    ")\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "  \"unet.h5\", \n",
    "  verbose = 1, \n",
    "  save_best_only = True\n",
    ")\n",
    "\n",
    "# LOSS Functions\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = keras.backend.sum(keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = keras.backend.sum(keras.backend.abs(y_true) + keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = keras.backend.sum(keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = keras.backend.sum(keras.backend.abs(y_true), -1) + keras.backend.sum(keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-spokesman",
   "metadata": {},
   "source": [
    "## Load Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "permanent-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(\"unet.h5\")):\n",
    "  model = keras.models.load_model(\"unet.h5\",\n",
    "    custom_objects = {\n",
    "      \"jaccard_distance_loss\": jaccard_distance_loss,\n",
    "      \"dice_coef\": dice_coef\n",
    "    }\n",
    "  )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-summit",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "national-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('input/X_val.npy')\n",
    "Y_val = np.load('input/Y_val.npy')\n",
    "\n",
    "\n",
    "with open('input/epochs.txt', 'r') as file:\n",
    "    steps_per_epoch = file.read().rstrip()\n",
    "\n",
    "steps_per_epoch = int(steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-university",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "center-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_val, dice_val = model.evaluate(X_val, Y_val, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train.npy')\n",
    "Y_train = np.load('input/Y_train.npy')\n",
    "\n",
    "\n",
    "iou_train, dice_train = model.evaluate(X_train, Y_train, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('input/X_test.npy')\n",
    "Y_test = np.load('input/Y_test.npy')\n",
    "\n",
    "\n",
    "iou_test, dice_test = model.evaluate(X_test, Y_test, verbose = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Jaccard distance (IoU) train: %f\" % iou_train)\n",
    "print(\"Dice coeffient train: %f\" % dice_train)\n",
    "print(\"Jaccard distance (IoU) validation: %f\" % iou_val)\n",
    "print(\"Dice coeffient validation: %f\" % dice_val)\n",
    "print(\"Jaccard distance (IoU) test: %f\" % iou_test)\n",
    "print(\"Dice coeffient test: %f\" % dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimages = X_train.shape[0]\n",
    "iou_train = []\n",
    "dice_train = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_train[idx:idx+1,:,:], Y_train[idx:idx+1,:,:], verbose = False)\n",
    "  iou_train.append(iou)\n",
    "  dice_train.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) train: %f (+-%f)\" % (np.mean(iou_train), np.std(iou_train)))\n",
    "print(\"Dice coeffient train: %f (+-%f)\" % (np.mean(dice_train), np.std(dice_train)))\n",
    "\n",
    "nimages = X_val.shape[0]\n",
    "iou_val = []\n",
    "dice_val = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_val[idx:idx+1,:,:], Y_val[idx:idx+1,:,:], verbose = False)\n",
    "  iou_val.append(iou)\n",
    "  dice_val.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) validation: %f (+-%f)\" % (np.mean(iou_val), np.std(iou_val)))\n",
    "print(\"Dice coeffient validation: %f (+-%f)\" % (np.mean(dice_val), np.std(dice_val)))\n",
    "\n",
    "\n",
    "nimages = X_test.shape[0]\n",
    "iou_test = []\n",
    "dice_test = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "  iou_test.append(iou)\n",
    "  dice_test.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) test: %f (+-%f)\" % (np.mean(iou_test), np.std(iou_test)))\n",
    "print(\"Dice coeffient test: %f (+-%f)\" % (np.mean(dice_test), np.std(dice_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "shenzhen_test_ids = []\n",
    "jsrt_test_ids = []\n",
    "montgomery_test_ids = []\n",
    "v7labs_test_ids = []\n",
    "other_test_ids = []\n",
    "\n",
    "count = 0\n",
    "datasets_ids = [shenzhen_test_ids, jsrt_test_ids, montgomery_test_ids, v7labs_test_ids, other_test_ids]\n",
    "with open(\"input/test_ids.txt\") as fp:\n",
    "    for line in fp:\n",
    "        new_list = line.strip()\n",
    "        datasets_ids[count].append(new_list)\n",
    "        count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "shenzhen_test_ids = ast.literal_eval(shenzhen_test_ids[0])\n",
    "jsrt_test_ids = ast.literal_eval(jsrt_test_ids[0])\n",
    "montgomery_test_ids = ast.literal_eval(montgomery_test_ids[0])\n",
    "v7labs_test_ids = ast.literal_eval(v7labs_test_ids[0])\n",
    "other_test_ids = ast.literal_eval(other_test_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimages = X_test.shape[0]\n",
    "iou_test = []\n",
    "dice_test = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in range(nimages):\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_test.append(iou)\n",
    "    dice_test.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) test: %f (+-%f)\" % (np.mean(iou_test), np.std(iou_test)))\n",
    "print(\"Dice coeffient test: %f (+-%f)\" % (np.mean(dice_test), np.std(dice_test)))\n",
    "\n",
    "\n",
    "iou_shenzhen = []\n",
    "dice_shenzhen = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in shenzhen_test_ids:\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_shenzhen.append(iou)\n",
    "    dice_shenzhen.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) Shenzhen: %f (+-%f)\" % (np.mean(iou_shenzhen), np.std(iou_shenzhen)))\n",
    "print(\"Dice coeffient Shenzhen: %f (+-%f)\" % (np.mean(dice_shenzhen), np.std(dice_shenzhen)))\n",
    "\n",
    "\n",
    "iou_montgomery = []\n",
    "dice_montgomery = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in montgomery_test_ids:\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_montgomery.append(iou)\n",
    "    dice_montgomery.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) Montgomery: %f (+-%f)\" % (np.mean(iou_montgomery), np.std(iou_montgomery)))\n",
    "print(\"Dice coeffient Montgomery: %f (+-%f)\" % (np.mean(dice_montgomery), np.std(dice_montgomery)))\n",
    "\n",
    "\n",
    "iou_jsrt = []\n",
    "dice_jsrt = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in jsrt_test_ids:\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_jsrt.append(iou)\n",
    "    dice_jsrt.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) JSRT: %f (+-%f)\" % (np.mean(iou_jsrt), np.std(iou_jsrt)))\n",
    "print(\"Dice coeffient JSRT: %f (+-%f)\" % (np.mean(dice_jsrt), np.std(dice_jsrt)))\n",
    "\n",
    "\n",
    "iou_v7labs = []\n",
    "dice_v7labs = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in v7labs_test_ids:\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_v7labs.append(iou)\n",
    "    dice_v7labs.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) v7labs: %f (+-%f)\" % (np.mean(iou_v7labs), np.std(iou_v7labs)))\n",
    "print(\"Dice coeffient v7labs: %f (+-%f)\" % (np.mean(dice_v7labs), np.std(dice_v7labs)))\n",
    "\n",
    "\n",
    "\n",
    "iou_manual = []\n",
    "dice_manual = []\n",
    "with tf.device(\"/gpu:1\"):\n",
    "  for idx in other_test_ids:\n",
    "    iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "    iou_manual.append(iou)\n",
    "    dice_manual.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) manual: %f (+-%f)\" % (np.mean(iou_manual), np.std(iou_manual)))\n",
    "print(\"Dice coeffient manual: %f (+-%f)\" % (np.mean(dice_manual), np.std(dice_manual)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-danger",
   "metadata": {},
   "source": [
    "## Visualizando a segmentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 26\n",
    "\n",
    "test_img = X_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "pred_mask = model.predict(test_img)\n",
    "pred_mask = np.uint8(pred_mask > 0.5)\n",
    "post_pred_mask = skimage.morphology.erosion(pred_mask[0,:,:,0], skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(post_pred_mask, skimage.morphology.square(10))\n",
    "\n",
    "\n",
    "f = plt.figure(figsize = (20, 10))\n",
    "f.add_subplot(1, 4, 1)\n",
    "plt.imshow(img_as_float64(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 2)\n",
    "plt.imshow(test_mask[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 3)\n",
    "plt.imshow(pred_mask[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 4)\n",
    "plt.imshow(post_pred_mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, mask):\n",
    "  crop_mask = mask > 0\n",
    "  m, n = mask.shape\n",
    "  crop_mask0, crop_mask1 = crop_mask.any(0), crop_mask.any(1)\n",
    "  col_start, col_end = crop_mask0.argmax(), n - crop_mask0[::-1].argmax()\n",
    "  row_start, row_end = crop_mask1.argmax(), m - crop_mask1[::-1].argmax()\n",
    "  return img[row_start:row_end, col_start:col_end], mask[row_start:row_end, col_start:col_end]\n",
    "  \n",
    "#idx = 70\n",
    "idx = 2\n",
    "test_img = X_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "pred_mask = model.predict(test_img)[0,:,:,0]\n",
    "pred_mask = np.uint8(pred_mask > 0.5)\n",
    "open_pred_mask = skimage.morphology.erosion(pred_mask, skimage.morphology.square(5))\n",
    "open_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(open_pred_mask, skimage.morphology.square(5))\n",
    "\n",
    "crop_img, crop_mask = crop_image(test_img[0,:,:,0], pred_mask)\n",
    "\n",
    "crop_img_masked = crop_img * crop_mask\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(2, 2, 1)\n",
    "plt.imshow(img_as_float64(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 2)\n",
    "plt.imshow(post_pred_mask, cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 3)\n",
    "plt.imshow(img_as_float64(crop_img), cmap = \"gray\")\n",
    "f.add_subplot(2, 2, 4)\n",
    "plt.imshow(crop_mask, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (20, 20))\n",
    "f.add_subplot(1, 1, 1)\n",
    "plt.imshow(img_as_float32(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (20, 20))\n",
    "f.add_subplot(1, 1, 1)\n",
    "plt.imshow(open_pred_mask, cmap = \"gray\")\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (20, 20))\n",
    "f.add_subplot(1, 1, 1)\n",
    "plt.imshow(post_pred_mask, cmap = \"gray\")\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (20, 20))\n",
    "f.add_subplot(1, 1, 1)\n",
    "plt.imshow(crop_img_masked, cmap = \"gray\")\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-tsunami",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folders = [ \"Cohen\", \"RSNA\", \"Actualmed\", \"Figure1\", \"KaggleCRD\", \"RICORD\", 'BIMCV', 'OCT'] #\"BIMCV\"\n",
    "pneumonia_folders = [\"Bacteria\", \"Fungi\", \"Virus\", \"Pneumonia\", \"Lung Opacity\"]\n",
    "pathogen_folders = [\"Bacteria\", \"Fungi\", \"Virus\", \"Pneumonia\", \"Lung Opacity\", \"COVID-19\", \"Normal\"]\n",
    "\n",
    "dest_folder = \"../2_Raw_Seg/\"\n",
    "root_folder = \"../2_Raw/\"\n",
    "#masks_folder = os.path.join(root_folder, \"Masks\")\n",
    "\n",
    "img_size = 400\n",
    "dim = (img_size,img_size)\n",
    "\n",
    "if os.path.isdir(dest_folder):\n",
    "  shutil.rmtree(dest_folder)\n",
    "\n",
    "if not os.path.isdir(dest_folder):\n",
    "  os.makedirs(dest_folder)\n",
    "  \n",
    "\n",
    "for path, subdirs, files in os.walk(root_folder):\n",
    "    for dirs in subdirs:\n",
    "        path = path.replace(root_folder, dest_folder)\n",
    "        dir_path = os.path.join(path, dirs)\n",
    "        print(dir_path)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "\n",
    "for path, subdirs, files in os.walk(root_folder):\n",
    "    for name in files:\n",
    "        img_path = os.path.join(path, name)\n",
    "        \n",
    "        print(img_path)\n",
    "        \n",
    "        if len(img_path.split(\"/\")) == 6:\n",
    "            ref, source, data, patgn, pat2, name_im = re.split(\"/\", img_path)\n",
    "            img_filename = os.path.join(dest_folder,data,patgn,pat2,name_im)\n",
    "        elif len(img_path.split(\"/\")) == 7:\n",
    "            ref, source, data, patgn, pat2, pat3, name_im = re.split(\"/\", img_path)\n",
    "            img_filename = os.path.join(dest_folder,data,patgn,pat2,pat3,name_im)\n",
    "        else:\n",
    "            ref, source, data, patgn, name_im = re.split(\"/\", img_path)\n",
    "            img_filename = os.path.join(dest_folder,data,patgn,name_im)\n",
    "            \n",
    "        mask_dir = \"Masks\"\n",
    "        mask_filename = os.path.join(dest_folder,data,mask_dir,name_im)\n",
    "     \n",
    "        if not mask_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "            mask_filename = mask_filename + \".png\"\n",
    "            \n",
    "        if not img_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "            img_filename = img_filename + \".png\"\n",
    "            \n",
    "        img = imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "        img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        print(img.shape)\n",
    "        img = img_as_float32(img).reshape((1, img_size, img_size, 1))\n",
    "    \n",
    "        mask_pred = model.predict(img)[0,:,:,0]\n",
    "        mask_pred = np.uint8(mask_pred > 0.5)\n",
    "        mask_pred = skimage.morphology.erosion(mask_pred, skimage.morphology.square(5))\n",
    "        mask_pred = skimage.morphology.dilation(mask_pred, skimage.morphology.square(10))\n",
    "        \n",
    "        img = img_as_ubyte(img[0,:,:,0])\n",
    "\n",
    "        crop_img, crop_mask = crop_image(img, mask_pred)\n",
    "        wdt, hgt = crop_img.shape\n",
    "        \n",
    "        if wdt < 200 or hgt < 200:\n",
    "            print(img_filename)\n",
    "            print(\"too small\")\n",
    "          #continue\n",
    "\n",
    "        crop_img = crop_img * crop_mask\n",
    "\n",
    "        crop_img = cv2.resize(crop_img, (300, 300), interpolation = cv2.INTER_CUBIC)\n",
    "        crop_mask = cv2.resize(crop_mask, (300, 300), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        imsave(os.path.join(mask_filename), crop_mask * 255)\n",
    "        imsave(os.path.join(img_filename), crop_img)\n",
    "        print('-----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-destination",
   "metadata": {},
   "source": [
    "## Predict GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folders = [ \"COVID-19_Imgs\", \"Normal_Imgs\", \"Pneumonia_Imgs\"]\n",
    "\n",
    "dest_folder = \"../augmentation/Results/Seg/\"\n",
    "root_folder = \"../augmentation/Results/\"\n",
    "#masks_folder = os.path.join(root_folder, \"Masks\")\n",
    "\n",
    "img_size = 400\n",
    "dim = (img_size,img_size)\n",
    "\n",
    "if os.path.isdir(dest_folder):\n",
    "  shutil.rmtree(dest_folder)\n",
    "\n",
    "if not os.path.isdir(dest_folder):\n",
    "  os.makedirs(dest_folder)\n",
    "  \n",
    "\n",
    "for source in source_folders:\n",
    "    for path, subdirs, files in os.walk(os.path.join(root_folder, source)):\n",
    "        for name in files:\n",
    "            img_path = os.path.join(path, name)\n",
    "\n",
    "            print(img_path)\n",
    "\n",
    "            ref, source, data, patgn, name_im = re.split(\"/\", img_path)\n",
    "            img_filename = img_path\n",
    "\n",
    "\n",
    "            mask_filename = os.path.join(dest_folder,patgn,name_im)\n",
    "            \n",
    "            if not mask_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "                mask_filename = mask_filename + \".png\"\n",
    "\n",
    "            if not img_filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "                img_filename = img_filename + \".png\"\n",
    "\n",
    "            img = imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            print(img.shape)\n",
    "            img = img_as_float32(img).reshape((1, img_size, img_size, 1))\n",
    "\n",
    "            mask_pred = model.predict(img)[0,:,:,0]\n",
    "            mask_pred = np.uint8(mask_pred > 0.5)\n",
    "            mask_pred = skimage.morphology.erosion(mask_pred, skimage.morphology.square(5))\n",
    "            mask_pred = skimage.morphology.dilation(mask_pred, skimage.morphology.square(10))\n",
    "\n",
    "            img = img_as_ubyte(img[0,:,:,0])\n",
    "\n",
    "            crop_img, crop_mask = crop_image(img, mask_pred)\n",
    "            wdt, hgt = crop_img.shape\n",
    "\n",
    "            if wdt < 200 or hgt < 200:\n",
    "                print(img_filename)\n",
    "                print(\"too small\")\n",
    "              #continue\n",
    "\n",
    "            crop_img = crop_img * crop_mask\n",
    "\n",
    "            crop_img = cv2.resize(crop_img, (300, 300), interpolation = cv2.INTER_CUBIC)\n",
    "            crop_mask = cv2.resize(crop_mask, (300, 300), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "            imsave(os.path.join(mask_filename), crop_mask * 255)\n",
    "            imsave(os.path.join(img_filename), crop_img)\n",
    "            print('-----------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
