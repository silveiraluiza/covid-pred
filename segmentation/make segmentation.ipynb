{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emerging-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_float32, img_as_ubyte\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma\n",
    ")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlike-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_learning_rate = keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor = \"loss\", \n",
    "  factor = 0.5, \n",
    "  patience = 3, \n",
    "  verbose = 1\n",
    ")\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "  \"unet.h5\", \n",
    "  verbose = 1, \n",
    "  save_best_only = True\n",
    ")\n",
    "\n",
    "# LOSS Functions\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth = 100):\n",
    "    intersection = keras.backend.sum(keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = keras.backend.sum(keras.backend.abs(y_true) + keras.backend.abs(y_pred), axis = -1)\n",
    "    jac = (intersection + smooth) / (union - intersection + smooth)\n",
    "    loss = (1 - jac) * smooth\n",
    "    return loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth = 1):\n",
    "    intersection = keras.backend.sum(keras.backend.abs(y_true * y_pred), axis = -1)\n",
    "    union = keras.backend.sum(keras.backend.abs(y_true), -1) + keras.backend.sum(keras.backend.abs(y_pred), -1)\n",
    "    return (2. * intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "permanent-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(\"unet.h5\")):\n",
    "  model = keras.models.load_model(\"unet.h5\",\n",
    "    custom_objects = {\n",
    "      \"jaccard_distance_loss\": jaccard_distance_loss,\n",
    "      \"dice_coef\": dice_coef\n",
    "    }\n",
    "  )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "national-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('input/X_val.npy')\n",
    "Y_val = np.load('input/Y_val.npy')\n",
    "\n",
    "with open('input/epochs.txt', 'r') as file:\n",
    "    steps_per_epoch = file.read().rstrip()\n",
    "\n",
    "steps_per_epoch = int(steps_per_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "center-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_val, dice_val = model.evaluate(X_val, Y_val, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pediatric-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('input/X_train.npy')\n",
    "Y_train = np.load('input/Y_train.npy')\n",
    "\n",
    "iou_train, dice_train = model.evaluate(X_train, Y_train, verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dress-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('input/X_test.npy')\n",
    "Y_test = np.load('input/Y_test.npy')\n",
    "\n",
    "iou_test, dice_test = model.evaluate(X_test, Y_test, verbose = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desperate-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance (IoU) train: 0.198845\n",
      "Dice coeffient train: 0.899309\n",
      "Jaccard distance (IoU) validation: 0.210787\n",
      "Dice coeffient validation: 0.893283\n",
      "Jaccard distance (IoU) test: 0.191380\n",
      "Dice coeffient test: 0.903078\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard distance (IoU) train: %f\" % iou_train)\n",
    "print(\"Dice coeffient train: %f\" % dice_train)\n",
    "print(\"Jaccard distance (IoU) validation: %f\" % iou_val)\n",
    "print(\"Dice coeffient validation: %f\" % dice_val)\n",
    "print(\"Jaccard distance (IoU) test: %f\" % iou_test)\n",
    "print(\"Dice coeffient test: %f\" % dice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "twelve-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance (IoU) train: 0.198845 (+-0.111525)\n",
      "Dice coeffient train: 0.899309 (+-0.056199)\n",
      "Jaccard distance (IoU) validation: 0.210788 (+-0.105555)\n",
      "Dice coeffient validation: 0.893283 (+-0.053236)\n",
      "Jaccard distance (IoU) test: 0.191380 (+-0.113436)\n",
      "Dice coeffient test: 0.903078 (+-0.057180)\n"
     ]
    }
   ],
   "source": [
    "nimages = X_train.shape[0]\n",
    "iou_train = []\n",
    "dice_train = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_train[idx:idx+1,:,:], Y_train[idx:idx+1,:,:], verbose = False)\n",
    "  iou_train.append(iou)\n",
    "  dice_train.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) train: %f (+-%f)\" % (np.mean(iou_train), np.std(iou_train)))\n",
    "print(\"Dice coeffient train: %f (+-%f)\" % (np.mean(dice_train), np.std(dice_train)))\n",
    "\n",
    "nimages = X_val.shape[0]\n",
    "iou_val = []\n",
    "dice_val = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_val[idx:idx+1,:,:], Y_val[idx:idx+1,:,:], verbose = False)\n",
    "  iou_val.append(iou)\n",
    "  dice_val.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) validation: %f (+-%f)\" % (np.mean(iou_val), np.std(iou_val)))\n",
    "print(\"Dice coeffient validation: %f (+-%f)\" % (np.mean(dice_val), np.std(dice_val)))\n",
    "\n",
    "\n",
    "nimages = X_test.shape[0]\n",
    "iou_test = []\n",
    "dice_test = []\n",
    "for idx in range(nimages):\n",
    "  iou, dice = model.evaluate(X_test[idx:idx+1,:,:], Y_test[idx:idx+1,:,:], verbose = False)\n",
    "  iou_test.append(iou)\n",
    "  dice_test.append(dice)\n",
    "\n",
    "print(\"Jaccard distance (IoU) test: %f (+-%f)\" % (np.mean(iou_test), np.std(iou_test)))\n",
    "print(\"Dice coeffient test: %f (+-%f)\" % (np.mean(dice_test), np.std(dice_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occupied-station",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Images of type float must be between -1 and 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ab4324fb2dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_ubyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/skimage/util/dtype.py\u001b[0m in \u001b[0;36mimg_as_ubyte\u001b[0;34m(image, force_copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/skimage/util/dtype.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(image, dtype, force_copy, uniform)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Images of type float must be between -1 and 1.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;31m# floating point -> integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# use float type that can represent output integer type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Images of type float must be between -1 and 1."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 50\n",
    "img_size = 400\n",
    "\n",
    "test_img = X_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "test_mask = Y_test[idx,:,:,:].reshape((1, img_size, img_size, 1))\n",
    "pred_mask = model.predict(test_img)\n",
    "pred_mask = np.uint8(pred_mask > 0.5)\n",
    "post_pred_mask = skimage.morphology.erosion(pred_mask[0,:,:,0], skimage.morphology.square(5))\n",
    "post_pred_mask = skimage.morphology.dilation(post_pred_mask, skimage.morphology.square(10))\n",
    "\n",
    "f = plt.figure(figsize = (20, 10))\n",
    "f.add_subplot(1, 4, 1)\n",
    "plt.imshow(img_as_ubyte(test_img[0,:,:,0]), cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 2)\n",
    "plt.imshow(test_mask[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 3)\n",
    "plt.imshow(pred_mask[0,:,:,0], cmap = \"gray\")\n",
    "f.add_subplot(1, 4, 4)\n",
    "plt.imshow(post_pred_mask, cmap = \"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
