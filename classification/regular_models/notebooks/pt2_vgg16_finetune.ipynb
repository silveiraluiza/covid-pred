{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guided-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus existem\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'result': {'id': 2058519653,\n",
       "  'is_bot': True,\n",
       "  'first_name': 'cnn_covid',\n",
       "  'username': 'cnn_covid_bot',\n",
       "  'can_join_groups': True,\n",
       "  'can_read_all_group_messages': False,\n",
       "  'supports_inline_queries': False}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "import cv2\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma, CLAHE\n",
    ")\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import telebot\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  try:\n",
    "    print(\"gpus existem\")\n",
    "    print(gpus)\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "TELEBOT_TOKEN = \"2058519653:AAG5Kf0Othtye8e13F5WPnBQQSdoCt47ifA\"\n",
    "\n",
    "bot = telebot.TeleBot(\"2058519653:AAG5Kf0Othtye8e13F5WPnBQQSdoCt47ifA\")\n",
    "bot.config['api_key'] = TELEBOT_TOKEN\n",
    "bot.get_me()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-symphony",
   "metadata": {},
   "source": [
    "## Augmentation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gross-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationSequence(keras.utils.Sequence):\n",
    "  def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "    self.x, self.y = x_set, y_set\n",
    "    self.batch_size = batch_size\n",
    "    self.augment = augmentations\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    \n",
    "    aug_x = np.zeros(batch_x.shape)\n",
    "    for idx in range(batch_x.shape[0]):\n",
    "      aug = self.augment(image = batch_x[idx,:,:])\n",
    "      aug_x[idx,:,:] = aug[\"image\"]\n",
    "\n",
    "    return np.stack((aug_x,) * 3, axis = -1), batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-present",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binary-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pi = open('input/train_dataset.pkl', 'rb') \n",
    "train_generator =  pickle.load(file_pi)\n",
    "\n",
    "X_val = np.load('input/X_val.npy')\n",
    "Y_val = np.load('input/Y_val.npy')\n",
    "\n",
    "steps_per_epoch = 321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "explicit-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.AugmentationSequence"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-inspection",
   "metadata": {},
   "source": [
    "## Model Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-rendering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 16,826,179\n",
      "Trainable params: 16,821,059\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(587)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_name = \"cache/tl_vgg16_finetune_cd.h5\"\n",
    "model = keras.models.load_model(model_name)\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indian-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "321/321 [==============================] - 141s 391ms/step - loss: 0.7100 - accuracy: 0.7306 - val_loss: 3.7639 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52455, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 2/100\n",
      "321/321 [==============================] - 111s 345ms/step - loss: 0.5104 - accuracy: 0.8005 - val_loss: 1.8863 - val_accuracy: 0.6329\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.52455 to 0.63289, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 3/100\n",
      "321/321 [==============================] - 112s 347ms/step - loss: 0.4360 - accuracy: 0.8310 - val_loss: 3.9788 - val_accuracy: 0.3235\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63289\n",
      "Epoch 4/100\n",
      "321/321 [==============================] - 112s 349ms/step - loss: 0.4038 - accuracy: 0.8522 - val_loss: 0.6609 - val_accuracy: 0.7194\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.63289 to 0.71941, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 5/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.3935 - accuracy: 0.8555 - val_loss: 0.3059 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.71941 to 0.91193, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 6/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.3733 - accuracy: 0.8645 - val_loss: 0.6269 - val_accuracy: 0.7833\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91193\n",
      "Epoch 7/100\n",
      "321/321 [==============================] - 112s 349ms/step - loss: 0.3516 - accuracy: 0.8717 - val_loss: 0.6944 - val_accuracy: 0.7217\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91193\n",
      "Epoch 8/100\n",
      "321/321 [==============================] - 112s 347ms/step - loss: 0.3444 - accuracy: 0.8694 - val_loss: 0.9832 - val_accuracy: 0.6586\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91193\n",
      "Epoch 9/100\n",
      "321/321 [==============================] - 112s 348ms/step - loss: 0.3359 - accuracy: 0.8758 - val_loss: 1.7034 - val_accuracy: 0.3554\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91193\n",
      "Epoch 10/100\n",
      "321/321 [==============================] - 112s 349ms/step - loss: 0.3093 - accuracy: 0.8891 - val_loss: 1.3110 - val_accuracy: 0.6438\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91193\n",
      "Epoch 11/100\n",
      "321/321 [==============================] - 110s 344ms/step - loss: 0.3039 - accuracy: 0.8885 - val_loss: 0.3012 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91193\n",
      "Epoch 12/100\n",
      "321/321 [==============================] - 111s 346ms/step - loss: 0.2820 - accuracy: 0.8934 - val_loss: 0.4791 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91193\n",
      "Epoch 13/100\n",
      "321/321 [==============================] - 111s 346ms/step - loss: 0.2878 - accuracy: 0.8935 - val_loss: 0.8226 - val_accuracy: 0.7779\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91193\n",
      "Epoch 14/100\n",
      "321/321 [==============================] - 113s 350ms/step - loss: 0.2801 - accuracy: 0.8955 - val_loss: 0.8178 - val_accuracy: 0.7607\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91193\n",
      "Epoch 15/100\n",
      "321/321 [==============================] - 114s 353ms/step - loss: 0.2694 - accuracy: 0.9023 - val_loss: 0.4523 - val_accuracy: 0.8277\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91193\n",
      "Epoch 16/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.2584 - accuracy: 0.9082 - val_loss: 0.7324 - val_accuracy: 0.7389\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91193\n",
      "Epoch 17/100\n",
      "321/321 [==============================] - 111s 347ms/step - loss: 0.2513 - accuracy: 0.9056 - val_loss: 1.2033 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91193\n",
      "Epoch 18/100\n",
      "321/321 [==============================] - 112s 347ms/step - loss: 0.2666 - accuracy: 0.9066 - val_loss: 0.4358 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91193\n",
      "Epoch 19/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.2380 - accuracy: 0.9136 - val_loss: 0.2155 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.91193 to 0.92829, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 20/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.2298 - accuracy: 0.9187 - val_loss: 0.6700 - val_accuracy: 0.7420\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92829\n",
      "Epoch 21/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.2400 - accuracy: 0.9086 - val_loss: 0.4225 - val_accuracy: 0.8574\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.92829\n",
      "Epoch 22/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.2163 - accuracy: 0.9230 - val_loss: 0.5684 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92829\n",
      "Epoch 23/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.2119 - accuracy: 0.9236 - val_loss: 0.5458 - val_accuracy: 0.7958\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92829\n",
      "Epoch 24/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1982 - accuracy: 0.9275 - val_loss: 0.2954 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92829\n",
      "Epoch 25/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1893 - accuracy: 0.9327 - val_loss: 0.3753 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92829\n",
      "Epoch 26/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1860 - accuracy: 0.9327 - val_loss: 0.2942 - val_accuracy: 0.9041\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92829\n",
      "Epoch 27/100\n",
      "321/321 [==============================] - 111s 343ms/step - loss: 0.1910 - accuracy: 0.9335 - val_loss: 0.4485 - val_accuracy: 0.8340\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92829\n",
      "Epoch 28/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.1764 - accuracy: 0.9370 - val_loss: 1.5211 - val_accuracy: 0.6493\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92829\n",
      "Epoch 29/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.1573 - accuracy: 0.9401 - val_loss: 0.3917 - val_accuracy: 0.8753\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92829\n",
      "Epoch 30/100\n",
      "321/321 [==============================] - 111s 346ms/step - loss: 0.1511 - accuracy: 0.9476 - val_loss: 0.9706 - val_accuracy: 0.7101\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92829\n",
      "Epoch 31/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.1538 - accuracy: 0.9433 - val_loss: 0.5080 - val_accuracy: 0.8480\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92829\n",
      "Epoch 32/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1493 - accuracy: 0.9470 - val_loss: 0.4164 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92829\n",
      "Epoch 33/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.1445 - accuracy: 0.9479 - val_loss: 0.2849 - val_accuracy: 0.9080\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92829\n",
      "Epoch 34/100\n",
      "321/321 [==============================] - 111s 343ms/step - loss: 0.1269 - accuracy: 0.9550 - val_loss: 0.3810 - val_accuracy: 0.9041\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.92829\n",
      "Epoch 35/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1293 - accuracy: 0.9538 - val_loss: 3.5698 - val_accuracy: 0.3476\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92829\n",
      "Epoch 36/100\n",
      "321/321 [==============================] - 109s 338ms/step - loss: 0.1315 - accuracy: 0.9516 - val_loss: 0.3332 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.92829\n",
      "Epoch 37/100\n",
      "321/321 [==============================] - 109s 339ms/step - loss: 0.1241 - accuracy: 0.9581 - val_loss: 0.3869 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92829\n",
      "Epoch 38/100\n",
      "321/321 [==============================] - 111s 346ms/step - loss: 0.1162 - accuracy: 0.9579 - val_loss: 0.4431 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92829\n",
      "Epoch 39/100\n",
      "321/321 [==============================] - 109s 338ms/step - loss: 0.1094 - accuracy: 0.9633 - val_loss: 0.3333 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.92829\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 111s 344ms/step - loss: 0.1177 - accuracy: 0.9587 - val_loss: 0.3489 - val_accuracy: 0.9041\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.92829\n",
      "Epoch 41/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.1186 - accuracy: 0.9610 - val_loss: 0.7884 - val_accuracy: 0.7724\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92829\n",
      "Epoch 42/100\n",
      "321/321 [==============================] - 109s 340ms/step - loss: 0.0907 - accuracy: 0.9719 - val_loss: 0.4076 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.92829\n",
      "Epoch 43/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.1127 - accuracy: 0.9614 - val_loss: 0.2434 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.92829\n",
      "Epoch 44/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0994 - accuracy: 0.9659 - val_loss: 0.3987 - val_accuracy: 0.8932\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.92829\n",
      "Epoch 45/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0792 - accuracy: 0.9735 - val_loss: 0.3550 - val_accuracy: 0.8971\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.92829\n",
      "Epoch 46/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0995 - accuracy: 0.9669 - val_loss: 0.2533 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.92829\n",
      "Epoch 47/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0886 - accuracy: 0.9704 - val_loss: 0.5747 - val_accuracy: 0.8418\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.92829\n",
      "Epoch 48/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0823 - accuracy: 0.9747 - val_loss: 0.4899 - val_accuracy: 0.8535\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.92829\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 49/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0550 - accuracy: 0.9838 - val_loss: 0.2519 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.92829\n",
      "Epoch 50/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0412 - accuracy: 0.9864 - val_loss: 0.2532 - val_accuracy: 0.9337\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.92829 to 0.93375, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 51/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.3632 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.93375\n",
      "Epoch 52/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.3242 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.93375\n",
      "Epoch 53/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0334 - accuracy: 0.9901 - val_loss: 0.3073 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.93375\n",
      "Epoch 54/100\n",
      "321/321 [==============================] - 108s 336ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.2797 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00054: val_accuracy improved from 0.93375 to 0.93531, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 55/100\n",
      "321/321 [==============================] - 109s 338ms/step - loss: 0.0398 - accuracy: 0.9875 - val_loss: 0.6649 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.93531\n",
      "Epoch 56/100\n",
      "321/321 [==============================] - 110s 340ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.5368 - val_accuracy: 0.8909\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.93531\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 57/100\n",
      "321/321 [==============================] - 109s 339ms/step - loss: 0.0238 - accuracy: 0.9932 - val_loss: 0.2966 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.93531\n",
      "Epoch 58/100\n",
      "321/321 [==============================] - 109s 338ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.3485 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.93531\n",
      "Epoch 59/100\n",
      "321/321 [==============================] - 109s 340ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.2767 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.93531\n",
      "Epoch 60/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.2726 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.93531\n",
      "Epoch 61/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.4242 - val_accuracy: 0.9026\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.93531\n",
      "Epoch 62/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.2598 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.93531 to 0.93998, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 63/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0107 - accuracy: 0.9981 - val_loss: 0.2920 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.93998\n",
      "Epoch 64/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.2935 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.93998\n",
      "Epoch 65/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.2901 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.93998\n",
      "Epoch 66/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.2876 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.93998\n",
      "Epoch 67/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.3090 - val_accuracy: 0.9376\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.93998\n",
      "Epoch 68/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.2925 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.93998\n",
      "Epoch 69/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0119 - accuracy: 0.9971 - val_loss: 0.2973 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.93998\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 70/100\n",
      "321/321 [==============================] - 112s 346ms/step - loss: 0.0156 - accuracy: 0.9951 - val_loss: 0.3023 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.93998\n",
      "Epoch 71/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.2943 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.93998\n",
      "Epoch 72/100\n",
      "321/321 [==============================] - 112s 347ms/step - loss: 0.0094 - accuracy: 0.9977 - val_loss: 0.2865 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00072: val_accuracy improved from 0.93998 to 0.94310, saving model to cache/tl_vgg16_finetune_cd.h5\n",
      "Epoch 73/100\n",
      "321/321 [==============================] - 111s 345ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.3051 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.94310\n",
      "Epoch 74/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.3081 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.94310\n",
      "Epoch 75/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.2927 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 76/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.2887 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.94310\n",
      "Epoch 77/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.3135 - val_accuracy: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.94310\n",
      "Epoch 78/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.2966 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.94310\n",
      "Epoch 79/100\n",
      "321/321 [==============================] - 111s 345ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.3135 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.94310\n",
      "Epoch 80/100\n",
      "321/321 [==============================] - 110s 344ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.3213 - val_accuracy: 0.9376\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 81/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.3020 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.94310\n",
      "Epoch 82/100\n",
      "321/321 [==============================] - 109s 339ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.3068 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.94310\n",
      "Epoch 83/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.2913 - val_accuracy: 0.9408\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.94310\n",
      "Epoch 84/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3141 - val_accuracy: 0.9376\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 85/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.3031 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.94310\n",
      "Epoch 86/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.3011 - val_accuracy: 0.9423\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.94310\n",
      "Epoch 87/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.3089 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 88/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.2990 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.94310\n",
      "Epoch 89/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.2988 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.94310\n",
      "Epoch 90/100\n",
      "321/321 [==============================] - 111s 344ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.3047 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "Epoch 91/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.3081 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.94310\n",
      "Epoch 92/100\n",
      "321/321 [==============================] - 109s 338ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.3013 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.94310\n",
      "Epoch 93/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.3102 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.94310\n",
      "Epoch 94/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.3101 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "Epoch 95/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 0.3061 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.94310\n",
      "Epoch 96/100\n",
      "321/321 [==============================] - 109s 340ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.2983 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.94310\n",
      "Epoch 97/100\n",
      "321/321 [==============================] - 110s 343ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.3071 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 98/100\n",
      "321/321 [==============================] - 111s 346ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 0.3039 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.94310\n",
      "Epoch 99/100\n",
      "321/321 [==============================] - 110s 342ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.3033 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.94310\n",
      "Epoch 100/100\n",
      "321/321 [==============================] - 110s 341ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.3065 - val_accuracy: 0.9408\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.94310\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n"
     ]
    }
   ],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "  model_name,\n",
    "  monitor = \"val_accuracy\",\n",
    "  verbose = 1, \n",
    "  save_best_only = True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reduce_learning_rate = keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor = \"loss\", \n",
    "  factor = 0.5, \n",
    "  patience = 3, \n",
    "  verbose = 1\n",
    ")\n",
    "\n",
    "start = time.time()    \n",
    "fit = model.fit(train_generator, \n",
    "    steps_per_epoch = steps_per_epoch, \n",
    "    epochs = 100,\n",
    "    validation_data = (X_val, Y_val),\n",
    "    callbacks = [\n",
    "      checkpointer,\n",
    "      reduce_learning_rate\n",
    "    ]\n",
    "  )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "final_train1 = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-attitude",
   "metadata": {},
   "source": [
    "### Save Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "corporate-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"input/time_train_2.txt\", \"wt\")\n",
    "n = text_file.write(str(final_train1))\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
