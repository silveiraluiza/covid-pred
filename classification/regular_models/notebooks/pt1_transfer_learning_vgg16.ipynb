{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "packed-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpus existem\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'result': {'id': 2058519653,\n",
       "  'is_bot': True,\n",
       "  'first_name': 'cnn_covid',\n",
       "  'username': 'cnn_covid_bot',\n",
       "  'can_join_groups': True,\n",
       "  'can_read_all_group_messages': False,\n",
       "  'supports_inline_queries': False}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "import cv2\n",
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, ShiftScaleRotate, ElasticTransform,\n",
    "    RandomBrightness, RandomContrast, RandomGamma, CLAHE\n",
    ")\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import telebot\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "  try:\n",
    "    print(\"gpus existem\")\n",
    "    print(gpus)\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "TELEBOT_TOKEN = \"2058519653:AAG5Kf0Othtye8e13F5WPnBQQSdoCt47ifA\"\n",
    "\n",
    "\n",
    "img_size = 300\n",
    "bot = telebot.TeleBot(\"2058519653:AAG5Kf0Othtye8e13F5WPnBQQSdoCt47ifA\")\n",
    "bot.config['api_key'] = TELEBOT_TOKEN\n",
    "bot.get_me()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-tract",
   "metadata": {},
   "source": [
    "## Augmentation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quantitative-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentationSequence(keras.utils.Sequence):\n",
    "  def __init__(self, x_set, y_set, batch_size, augmentations):\n",
    "    self.x, self.y = x_set, y_set\n",
    "    self.batch_size = batch_size\n",
    "    self.augment = augmentations\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "    \n",
    "    aug_x = np.zeros(batch_x.shape)\n",
    "    for idx in range(batch_x.shape[0]):\n",
    "      aug = self.augment(image = batch_x[idx,:,:])\n",
    "      aug_x[idx,:,:] = aug[\"image\"]\n",
    "\n",
    "    return np.stack((aug_x,) * 3, axis = -1), batch_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-teens",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedicated-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pi = open('input/train_dataset.pkl', 'rb') \n",
    "train_generator =  pickle.load(file_pi)\n",
    "\n",
    "X_val = np.load('input/X_val.npy')\n",
    "Y_val = np.load('input/Y_val.npy')\n",
    "\n",
    "steps_per_epoch = 321"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-woman",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electrical-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "  inputs = keras.Input(shape = (img_size, img_size, 3))\n",
    "  \n",
    "  base_model = keras.applications.VGG16(\n",
    "    weights = \"imagenet\",\n",
    "    include_top = False,\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "  )\n",
    "  base_model.trainable = False\n",
    "  \n",
    "  x = base_model(inputs, training = False)\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "  x = keras.layers.Dense(1024, activation = \"relu\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Dropout(0.5)(x)\n",
    "  x = keras.layers.Dense(1024, activation = \"relu\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Dropout(0.5)(x)\n",
    "  x = keras.layers.Dense(512, activation = \"relu\")(x)\n",
    "  x = keras.layers.BatchNormalization()(x)\n",
    "  x = keras.layers.Dropout(0.5)(x)\n",
    "  output = keras.layers.Dense(3, activation = 'softmax')(x)\n",
    "\n",
    "  model = keras.Model(inputs = inputs, outputs = output)\n",
    "\n",
    "  return model, base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-purse",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "experienced-finland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Epoch 1/50\n",
      "321/321 [==============================] - 124s 350ms/step - loss: 1.0897 - accuracy: 0.6374 - val_loss: 0.8217 - val_accuracy: 0.6508\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65082, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 2/50\n",
      "321/321 [==============================] - 102s 318ms/step - loss: 0.7653 - accuracy: 0.6976 - val_loss: 0.5623 - val_accuracy: 0.7888\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65082 to 0.78878, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 3/50\n",
      "321/321 [==============================] - 100s 312ms/step - loss: 0.6717 - accuracy: 0.7346 - val_loss: 0.4909 - val_accuracy: 0.8176\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78878 to 0.81761, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 4/50\n",
      "321/321 [==============================] - 101s 314ms/step - loss: 0.6141 - accuracy: 0.7551 - val_loss: 0.4937 - val_accuracy: 0.8020\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.81761\n",
      "Epoch 5/50\n",
      "321/321 [==============================] - 102s 317ms/step - loss: 0.5850 - accuracy: 0.7709 - val_loss: 0.5706 - val_accuracy: 0.7693\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81761\n",
      "Epoch 6/50\n",
      "321/321 [==============================] - 101s 314ms/step - loss: 0.5881 - accuracy: 0.7666 - val_loss: 0.4308 - val_accuracy: 0.8394\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81761 to 0.83944, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 7/50\n",
      "321/321 [==============================] - 101s 314ms/step - loss: 0.5722 - accuracy: 0.7729 - val_loss: 0.6547 - val_accuracy: 0.7553\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.83944\n",
      "Epoch 8/50\n",
      "321/321 [==============================] - 99s 309ms/step - loss: 0.5635 - accuracy: 0.7771 - val_loss: 0.7130 - val_accuracy: 0.7163\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83944\n",
      "Epoch 9/50\n",
      "321/321 [==============================] - 99s 308ms/step - loss: 0.5422 - accuracy: 0.7961 - val_loss: 0.5615 - val_accuracy: 0.8059\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83944\n",
      "Epoch 10/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.5413 - accuracy: 0.7879 - val_loss: 0.4447 - val_accuracy: 0.8309\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83944\n",
      "Epoch 11/50\n",
      "321/321 [==============================] - 101s 313ms/step - loss: 0.5406 - accuracy: 0.7846 - val_loss: 0.6112 - val_accuracy: 0.7366\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83944\n",
      "Epoch 12/50\n",
      "321/321 [==============================] - 100s 311ms/step - loss: 0.5354 - accuracy: 0.7935 - val_loss: 0.6979 - val_accuracy: 0.7537\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83944\n",
      "Epoch 13/50\n",
      "321/321 [==============================] - 100s 310ms/step - loss: 0.5275 - accuracy: 0.7953 - val_loss: 0.6172 - val_accuracy: 0.7810\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83944\n",
      "Epoch 14/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.5281 - accuracy: 0.7988 - val_loss: 0.5537 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83944\n",
      "Epoch 15/50\n",
      "321/321 [==============================] - 103s 320ms/step - loss: 0.5245 - accuracy: 0.7941 - val_loss: 0.4360 - val_accuracy: 0.8363\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83944\n",
      "Epoch 16/50\n",
      "321/321 [==============================] - 100s 312ms/step - loss: 0.5272 - accuracy: 0.7990 - val_loss: 0.4685 - val_accuracy: 0.8207\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83944\n",
      "Epoch 17/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.5110 - accuracy: 0.8007 - val_loss: 0.4189 - val_accuracy: 0.8457\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83944 to 0.84567, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 18/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.5198 - accuracy: 0.7994 - val_loss: 0.5243 - val_accuracy: 0.7935\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84567\n",
      "Epoch 19/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.5092 - accuracy: 0.8039 - val_loss: 0.4120 - val_accuracy: 0.8511\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84567 to 0.85113, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 20/50\n",
      "321/321 [==============================] - 104s 322ms/step - loss: 0.5032 - accuracy: 0.8068 - val_loss: 0.4809 - val_accuracy: 0.8106\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85113\n",
      "Epoch 21/50\n",
      "321/321 [==============================] - 99s 309ms/step - loss: 0.5048 - accuracy: 0.7996 - val_loss: 0.9420 - val_accuracy: 0.6251\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85113\n",
      "Epoch 22/50\n",
      "321/321 [==============================] - 100s 311ms/step - loss: 0.5121 - accuracy: 0.7992 - val_loss: 0.4557 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85113\n",
      "Epoch 23/50\n",
      "321/321 [==============================] - 99s 307ms/step - loss: 0.4899 - accuracy: 0.8107 - val_loss: 0.4240 - val_accuracy: 0.8348\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85113\n",
      "Epoch 24/50\n",
      "321/321 [==============================] - 100s 310ms/step - loss: 0.5016 - accuracy: 0.8013 - val_loss: 0.6534 - val_accuracy: 0.7334\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85113\n",
      "Epoch 25/50\n",
      "321/321 [==============================] - 101s 313ms/step - loss: 0.4913 - accuracy: 0.8068 - val_loss: 0.6528 - val_accuracy: 0.7560\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85113\n",
      "Epoch 26/50\n",
      "321/321 [==============================] - 99s 308ms/step - loss: 0.4915 - accuracy: 0.8107 - val_loss: 0.5147 - val_accuracy: 0.7981\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85113\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/50\n",
      "321/321 [==============================] - 101s 314ms/step - loss: 0.4701 - accuracy: 0.8195 - val_loss: 0.3948 - val_accuracy: 0.8542\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85113 to 0.85425, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 28/50\n",
      "321/321 [==============================] - 99s 308ms/step - loss: 0.4692 - accuracy: 0.8261 - val_loss: 0.3840 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85425 to 0.86126, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 29/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.4541 - accuracy: 0.8212 - val_loss: 0.3899 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86126\n",
      "Epoch 30/50\n",
      "321/321 [==============================] - 100s 311ms/step - loss: 0.4499 - accuracy: 0.8232 - val_loss: 0.3623 - val_accuracy: 0.8504\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86126\n",
      "Epoch 31/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.4454 - accuracy: 0.8273 - val_loss: 0.3746 - val_accuracy: 0.8527\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86126\n",
      "Epoch 32/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.4476 - accuracy: 0.8306 - val_loss: 0.5075 - val_accuracy: 0.8028\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86126\n",
      "Epoch 33/50\n",
      "321/321 [==============================] - 100s 312ms/step - loss: 0.4309 - accuracy: 0.8343 - val_loss: 0.3537 - val_accuracy: 0.8652\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.86126 to 0.86516, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 34/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.4417 - accuracy: 0.8278 - val_loss: 0.3681 - val_accuracy: 0.8581\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86516\n",
      "Epoch 35/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.4272 - accuracy: 0.8358 - val_loss: 0.3782 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86516\n",
      "Epoch 36/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.4319 - accuracy: 0.8337 - val_loss: 0.4051 - val_accuracy: 0.8402\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86516\n",
      "Epoch 37/50\n",
      "321/321 [==============================] - 99s 308ms/step - loss: 0.4367 - accuracy: 0.8304 - val_loss: 0.3921 - val_accuracy: 0.8519\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86516\n",
      "Epoch 38/50\n",
      "321/321 [==============================] - 101s 315ms/step - loss: 0.4223 - accuracy: 0.8292 - val_loss: 0.3448 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_accuracy improved from 0.86516 to 0.87373, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 39/50\n",
      "321/321 [==============================] - 103s 319ms/step - loss: 0.4362 - accuracy: 0.8300 - val_loss: 0.3437 - val_accuracy: 0.8683\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.87373\n",
      "Epoch 40/50\n",
      "321/321 [==============================] - 100s 313ms/step - loss: 0.4274 - accuracy: 0.8349 - val_loss: 0.3475 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.87373\n",
      "Epoch 41/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.4282 - accuracy: 0.8331 - val_loss: 0.3606 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87373\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/50\n",
      "321/321 [==============================] - 100s 311ms/step - loss: 0.4214 - accuracy: 0.8347 - val_loss: 0.3394 - val_accuracy: 0.8753\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.87373 to 0.87529, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 43/50\n",
      "321/321 [==============================] - 101s 313ms/step - loss: 0.4232 - accuracy: 0.8382 - val_loss: 0.3375 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87529\n",
      "Epoch 44/50\n",
      "321/321 [==============================] - 100s 312ms/step - loss: 0.4093 - accuracy: 0.8430 - val_loss: 0.3313 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.87529 to 0.87685, saving model to cache/tl_vgg16_cd.h5\n",
      "Epoch 45/50\n",
      "321/321 [==============================] - 100s 313ms/step - loss: 0.4077 - accuracy: 0.8405 - val_loss: 0.3519 - val_accuracy: 0.8628\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87685\n",
      "Epoch 46/50\n",
      "321/321 [==============================] - 100s 310ms/step - loss: 0.4009 - accuracy: 0.8413 - val_loss: 0.3667 - val_accuracy: 0.8605\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87685\n",
      "Epoch 47/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.3969 - accuracy: 0.8495 - val_loss: 0.3309 - val_accuracy: 0.8714\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.87685\n",
      "Epoch 48/50\n",
      "321/321 [==============================] - 102s 318ms/step - loss: 0.3915 - accuracy: 0.8468 - val_loss: 0.3267 - val_accuracy: 0.8706\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87685\n",
      "Epoch 49/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.4027 - accuracy: 0.8464 - val_loss: 0.3310 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87685\n",
      "Epoch 50/50\n",
      "321/321 [==============================] - 101s 316ms/step - loss: 0.3982 - accuracy: 0.8495 - val_loss: 0.3313 - val_accuracy: 0.8737\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87685\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(587)\n",
    "\n",
    "reduce_learning_rate = keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor = \"loss\", \n",
    "  factor = 0.5, \n",
    "  patience = 3, \n",
    "  verbose = 1\n",
    ")\n",
    "\n",
    "model_name = \"cache/tl_vgg16_cd.h5\"\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "  model_name,\n",
    "  monitor = \"val_accuracy\",\n",
    "  verbose = 1, \n",
    "  save_best_only = True\n",
    ")\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "if (os.path.exists(model_name)):\n",
    "  model = keras.models.load_model(model_name)\n",
    "  print(\"existe\")\n",
    "  \n",
    "else:\n",
    "  model, base_model = create_model()\n",
    "  adam_opt = keras.optimizers.Adam(learning_rate = 0.001 )\n",
    "  model.compile(optimizer = adam_opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "  start = time.time()    \n",
    "  fit = model.fit(train_generator, \n",
    "    steps_per_epoch = steps_per_epoch, \n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, Y_val),\n",
    "    callbacks = [\n",
    "      checkpointer,\n",
    "      reduce_learning_rate\n",
    "    ]\n",
    "  )\n",
    "  end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mineral-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 9, 9, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 16,826,179\n",
      "Trainable params: 2,106,371\n",
      "Non-trainable params: 14,719,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loved-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train1 = end-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-edgar",
   "metadata": {},
   "source": [
    "## Create Finetuning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "split-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(587)\n",
    "\n",
    "model_name = \"cache/tl_vgg16_finetune_cd.h5\"\n",
    "\n",
    "if (os.path.exists(model_name)):\n",
    "  print(\"existe\")\n",
    "  model = keras.models.load_model(model_name)\n",
    "  \n",
    "else:\n",
    "  base_model.trainable = True\n",
    "  adam_opt = keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "  model.compile(optimizer = adam_opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "  model.save('cache/tl_vgg16_finetune_cd.h5')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-anatomy",
   "metadata": {},
   "source": [
    "### Save times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unusual-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"input/time_train.txt\", \"wt\")\n",
    "n = text_file.write(str(final_train1))\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
